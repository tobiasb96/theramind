<!-- Audio Input Modal -->
<div id="audio-input-modal" tabindex="-1" aria-hidden="true" class="hidden overflow-y-auto overflow-x-hidden fixed top-0 right-0 left-0 z-50 justify-center items-center w-full md:inset-0 h-[calc(100%-1rem)] max-h-full">
    <div class="relative p-4 w-full max-w-2xl max-h-full">
        <div class="relative bg-white rounded-lg shadow">
            <!-- Modal header -->
            <div class="flex items-center justify-between p-4 md:p-5 border-b rounded-t border-gray-200">
                <h3 class="text-lg font-semibold text-gray-900">
                    Audio hinzufügen
                </h3>
                <button type="button" class="text-gray-400 bg-transparent hover:bg-gray-200 hover:text-gray-900 rounded-lg text-sm w-8 h-8 ms-auto inline-flex justify-center items-center" data-modal-toggle="audio-input-modal">
                    <svg class="w-3 h-3" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 14 14">
                        <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m1 1 6 6m0 0 6 6M7 7l6-6M7 7l-6 6"/>
                    </svg>
                    <span class="sr-only">Close modal</span>
                </button>
            </div>
            
            <!-- Modal body with tabs -->
            <div class="p-4 md:p-5">
                <!-- Tab Navigation -->
                <div class="text-sm font-medium text-center text-gray-500 border-b border-gray-200 mb-4">
                    <ul class="flex flex-wrap -mb-px">
                        <li class="mr-2">
                            <button class="audio-tab-btn inline-block p-4 border-b-2 border-blue-600 text-blue-600 rounded-t-lg" 
                                    data-tab="record" onclick="switchAudioTab('record')">
                                <svg class="w-4 h-4 mr-2 inline" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"/>
                                </svg>
                                Aufnehmen
                            </button>
                        </li>
                        <li class="mr-2">
                            <button class="audio-tab-btn inline-block p-4 border-b-2 border-transparent rounded-t-lg hover:text-gray-600 hover:border-gray-300" 
                                    data-tab="upload" onclick="switchAudioTab('upload')">
                                <svg class="w-4 h-4 mr-2 inline" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12"/>
                                </svg>
                                Audio hochladen
                            </button>
                        </li>
                    </ul>
                </div>
                
                <!-- Record Tab Content -->
                <div id="audio-record-tab" class="audio-tab-content">
                    <!-- Info Banner -->
                    <div class="bg-blue-50 border border-blue-200 rounded-lg p-4 mb-4">
                        <div class="flex items-start">
                            <svg class="w-5 h-5 text-blue-600 mt-0.5 mr-3" fill="currentColor" viewBox="0 0 20 20">
                                <path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zM9 9a1 1 0 000 2v3a1 1 0 001 1h1a1 1 0 100-2v-3a1 1 0 00-1-1H9z" clip-rule="evenodd"/>
                            </svg>
                            <div class="text-sm">
                                <p class="font-medium text-blue-900">Automatische Transkription</p>
                                <p class="text-blue-700 mt-1">Audio wird transkribiert und KI-Notizen können generiert werden.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Active Recording Warning -->
                    <div id="active-recording-warning" class="hidden bg-amber-50 border border-amber-200 rounded-lg p-4 mb-4">
                        <div class="flex items-start">
                            <svg class="w-5 h-5 text-amber-600 mt-0.5 mr-3" fill="currentColor" viewBox="0 0 20 20">
                                <path fill-rule="evenodd" d="M8.257 3.099c.765-1.36 2.722-1.36 3.486 0l5.58 9.92c.75 1.334-.213 2.98-1.742 2.98H4.42c-1.53 0-2.493-1.646-1.743-2.98l5.58-9.92zM11 13a1 1 0 11-2 0 1 1 0 012 0zm-1-8a1 1 0 00-1 1v3a1 1 0 002 0V6a1 1 0 00-1-1z" clip-rule="evenodd"/>
                            </svg>
                            <div class="text-sm">
                                <p class="font-medium text-amber-900">Aufnahme läuft im Hintergrund</p>
                                <p class="text-amber-700 mt-1">Eine Aufnahme wurde fortgesetzt. Sie können diese beenden oder fortfahren.</p>
                            </div>
                        </div>
                    </div>

                    <div class="flex flex-col items-center space-y-4">
                        <!-- Recording Button -->
                        <button id="record-toggle" type="button" class="relative w-20 h-20 rounded-full bg-blue-600 hover:bg-blue-700 focus:ring-4 focus:outline-none focus:ring-blue-300 transition-all duration-200 flex items-center justify-center group">
                            <svg id="record-icon" class="w-8 h-8 text-white transition-all duration-200" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                <path id="record-icon-path" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9v3a5.006 5.006 0 0 1-5 5h-4a5.006 5.006 0 0 1-5-5V9m7 9v3m-3 0h6M11 3h2a3 3 0 0 1 3 3v5a3 3 0 0 1-3 3h-2a3 3 0 0 1-3-3V6a3 3 0 0 1 3-3Z"/>
                            </svg>
                            <div id="recording-pulse" class="absolute inset-0 rounded-full bg-red-500 opacity-0"></div>
                        </button>

                        <!-- Recording Status -->
                        <div id="recording-status" class="text-center">
                            <div id="recording-indicator" class="hidden flex items-center justify-center space-x-2">
                                <div class="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
                                <span id="recording-time" class="text-lg font-mono text-red-600">00:00</span>
                            </div>
                            <p id="record-instruction" class="text-sm text-gray-600 mt-2">Klicken zum Starten</p>
                        </div>

                        <!-- Audio Visualizer -->
                        <div id="audio-visualizer" class="hidden w-full max-w-sm">
                            <canvas id="visualizer-canvas" width="300" height="60" class="w-full h-15 bg-gray-50 rounded-lg border"></canvas>
                        </div>

                        <!-- Live Therapeutic Observations (visible during recording) -->
                        <div id="live-observations" class="hidden w-full">
                            <div class="bg-blue-50 rounded-lg p-4 border border-blue-200">
                                <label for="live-therapeutic-observations" class="block mb-2 text-sm font-medium text-blue-900">
                                    Therapeutische Beobachtungen (während der Aufnahme)
                                </label>
                                <textarea id="live-therapeutic-observations" rows="3" 
                                          class="bg-white border border-blue-300 text-gray-900 text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-2.5" 
                                          placeholder="z.B. Patient schafft es nicht den Augenkontakt zu halten, zeigt Anzeichen von Nervosität, erwähnt Schlafprobleme seit Medikamentenumstellung..."></textarea>
                                <p class="mt-1 text-xs text-blue-600">Du kannst während der Aufnahme Notizen machen - diese werden automatisch gespeichert.</p>
                            </div>
                        </div>

                        <!-- Audio Preview -->
                        <div id="audio-preview" class="hidden w-full">
                            <div class="bg-gray-50 rounded-lg p-4 border">
                                <div class="flex items-center justify-between mb-2">
                                    <h4 class="text-sm font-medium text-gray-900">Aufnahme</h4>
                                    <button type="button" id="delete-recording" class="text-red-600 hover:text-red-800 text-sm">
                                        <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 20 20">
                                            <path fill-rule="evenodd" d="M9 2a1 1 0 000 2h2a1 1 0 100-2H9z" clip-rule="evenodd"/>
                                            <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414L7.586 12l-1.293 1.293a1 1 0 101.414 1.414L9 13.414l2.293 2.293a1 1 0 001.414-1.414L11.414 12l1.293-1.293z" clip-rule="evenodd"/>
                                        </svg>
                                    </button>
                                </div>
                                <audio id="recorded-audio" controls class="w-full mb-4"></audio>
                                
                                <!-- Therapeutic Observations Field -->
                                <div class="mb-4">
                                    <label for="therapeutic-observations" class="block mb-2 text-sm font-medium text-gray-900">Therapeutische Beobachtungen</label>
                                    <textarea id="therapeutic-observations" rows="4" 
                                              class="bg-gray-50 border border-gray-300 text-gray-900 text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-2.5" 
                                              placeholder="Notiere hier zusätzliche therapeutische Beobachtungen zu dieser Aufnahme..."></textarea>
                                    <p class="mt-1 text-xs text-gray-500">Diese Notizen werden zusammen mit der Transkription für die KI-Analyse verwendet.</p>
                                </div>
                                
                                <!-- Submit Form -->
                                <form method="post" enctype="multipart/form-data" action="{% url 'inputs:add_audio_input' document_type=document_type document_id=document.pk %}">
                                    {% csrf_token %}
                                    <input type="hidden" name="audio_type" value="recording">
                                    <input type="file" name="audio_file" id="recorded-audio-file" class="hidden">
                                    <input type="hidden" name="therapeutic_observations" id="therapeutic-observations-input">
                                    
                                    <div class="flex justify-center space-x-2">
                                        <button type="button" onclick="resetRecording()" class="py-2 px-3 text-sm font-medium text-gray-500 bg-white rounded-lg border border-gray-200 hover:bg-gray-100 focus:ring-4 focus:outline-none focus:ring-gray-300">
                                            Erneut aufnehmen
                                        </button>
                                        <button type="submit" class="bg-blue-700 text-white px-5 py-2 rounded hover:bg-blue-800 focus:ring-4 focus:outline-none focus:ring-blue-300">
                                            Aufnahme speichern
                                        </button>
                                    </div>
                                </form>
                            </div>
                        </div>
                    </div>
                    
                    <div id="recording-error" class="hidden text-center text-red-600 mt-4">
                        <p>Fehler beim Zugriff auf das Mikrofon. Bitte überprüfe die Browser-Berechtigungen.</p>
                    </div>
                </div>
                
                <!-- Upload Tab Content -->
                <div id="audio-upload-tab" class="audio-tab-content hidden">
                    <form method="post" enctype="multipart/form-data" action="{% url 'inputs:add_audio_input' document_type=document_type document_id=document.pk %}">
                        {% csrf_token %}
                        <input type="hidden" name="audio_type" value="upload">
                        
                        <div class="mb-4">
                            <label for="audio-file-upload" class="block mb-2 text-sm font-medium text-gray-900">Audio-Datei auswählen</label>
                            <input type="file" name="audio_file" id="audio-file-upload" accept="audio/*" 
                                   class="block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-blue-50 file:text-blue-700 hover:file:bg-blue-100" 
                                   required>
                            <p class="mt-1 text-sm text-gray-500">Unterstützte Formate: MP3, WAV, M4A, FLAC (max. 25MB)</p>
                        </div>
                        
                        <div class="flex justify-end space-x-2">
                            <button type="button" data-modal-toggle="audio-input-modal" class="py-2 px-3 text-sm font-medium text-gray-500 bg-white rounded-lg border border-gray-200 hover:bg-gray-100 focus:ring-4 focus:outline-none focus:ring-gray-300">
                                Abbrechen
                            </button>
                            <button type="submit" class="bg-blue-700 text-white px-5 py-2 rounded hover:bg-blue-800 focus:ring-4 focus:outline-none focus:ring-blue-300">
                                Audio hochladen
                            </button>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
// Enhanced Audio Recording with Persistence and Data Loss Prevention
(function() {
    // Global state key for persistence
    const STORAGE_KEY = 'theramind_audio_recording_state';
    
    // Scoped variables
    let mediaRecorder;
    let recordedChunks = [];
    let recordingTimer;
    let recordingSeconds = 0;
    let isRecording = false;
    let audioContext;
    let analyser;
    let dataArray;
    let animationId;
    let recordingStartTime = null;
    let hasUnsavedData = false;
    let isInitialized = false;

    // Tab switching functionality
    function switchAudioTab(tabName) {
        // Hide all tab contents
        document.querySelectorAll('.audio-tab-content').forEach(tab => {
            tab.classList.add('hidden');
        });
        
        // Remove active state from all tab buttons
        document.querySelectorAll('.audio-tab-btn').forEach(btn => {
            btn.classList.remove('border-blue-600', 'text-blue-600');
            btn.classList.add('border-transparent');
        });
        
        // Show selected tab content
        document.getElementById(`audio-${tabName}-tab`).classList.remove('hidden');
        
        // Add active state to selected tab button
        const activeBtn = document.querySelector(`[data-tab="${tabName}"]`);
        activeBtn.classList.add('border-blue-600', 'text-blue-600');
        activeBtn.classList.remove('border-transparent');
    }

    // Make switchAudioTab available globally
    window.switchAudioTab = switchAudioTab;

    // Persistence functions
    function saveState() {
        const liveObservations = document.getElementById('live-therapeutic-observations');
        const state = {
            isRecording: isRecording,
            recordingSeconds: recordingSeconds,
            recordingStartTime: recordingStartTime,
            hasRecordedData: recordedChunks.length > 0,
            therapeuticObservations: liveObservations ? liveObservations.value : '',
            timestamp: Date.now()
        };
        
        // Save recorded chunks as base64 for persistence
        if (recordedChunks.length > 0) {
            try {
                const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                const reader = new FileReader();
                reader.onload = function() {
                    state.recordedDataURL = reader.result;
                    sessionStorage.setItem(STORAGE_KEY, JSON.stringify(state));
                };
                reader.readAsDataURL(blob);
                return;
            } catch (e) {
                console.warn('Failed to save recorded chunks:', e);
            }
        }
        
        sessionStorage.setItem(STORAGE_KEY, JSON.stringify(state));
    }

    function loadState() {
        try {
            const saved = sessionStorage.getItem(STORAGE_KEY);
            if (saved) {
                const state = JSON.parse(saved);
                // Only restore if less than 30 minutes old
                const MAX_STATE_AGE = 1800000; // 30 minutes
                if (Date.now() - state.timestamp < MAX_STATE_AGE) {
                    return state;
                }
                // Clean up expired state
                sessionStorage.removeItem(STORAGE_KEY);
            }
        } catch (e) {
            console.warn('Failed to load audio recording state:', e);
            sessionStorage.removeItem(STORAGE_KEY);
        }
        return null;
    }

    async function restoreRecordedChunks(dataURL) {
        if (!dataURL) return;
        
        try {
            const response = await fetch(dataURL);
            const blob = await response.blob();
            recordedChunks = [blob];
        } catch (e) {
            console.warn('Failed to restore recorded chunks:', e);
            recordedChunks = [];
        }
    }

    function clearState() {
        sessionStorage.removeItem(STORAGE_KEY);
        hasUnsavedData = false;
    }

    // Navigation warning functions
    function enableNavigationWarning() {
        hasUnsavedData = true;
        window.addEventListener('beforeunload', handleBeforeUnload);
    }

    function disableNavigationWarning() {
        hasUnsavedData = false;
        window.removeEventListener('beforeunload', handleBeforeUnload);
    }

    function handleBeforeUnload(e) {
        if (hasUnsavedData) {
            const message = 'Sie haben eine ungespeicherte Audioaufnahme. Möchten Sie die Seite wirklich verlassen?';
            e.preventDefault();
            e.returnValue = message;
            return message;
        }
    }

    // Initialize modal
    function initializeModal() {
        if (isInitialized) return;
        
        const recordToggle = document.getElementById('record-toggle');
        const deleteRecordingBtn = document.getElementById('delete-recording');
        
        if (recordToggle) {
            recordToggle.addEventListener('click', toggleRecording);
        }
        
        if (deleteRecordingBtn) {
            deleteRecordingBtn.addEventListener('click', resetRecording);
        }
        
        // Restore state if available
        const savedState = loadState();
        if (savedState) {
            setTimeout(async () => {
                await restoreFromState(savedState);
            }, 100);
        }
        
        isInitialized = true;
    }

    // Restore from saved state
    async function restoreFromState(state) {
        if (state.hasRecordedData && state.recordedDataURL) {
            await restoreRecordedChunks(state.recordedDataURL);
        }
        
        if (state.therapeuticObservations) {
            const liveObservations = document.getElementById('live-therapeutic-observations');
            const therapeuticObservations = document.getElementById('therapeutic-observations');
            if (liveObservations) liveObservations.value = state.therapeuticObservations;
            if (therapeuticObservations) therapeuticObservations.value = state.therapeuticObservations;
        }
        
        recordingSeconds = state.recordingSeconds || 0;
        recordingStartTime = state.recordingStartTime;
        
        if (state.isRecording) {
            // Resume recording if it was active
            isRecording = true;
            updateRecordingUI();
            startTimer();
        } else if (state.hasRecordedData) {
            // Show preview if there's recorded data
            showRecordingPreview();
        }
    }

async function toggleRecording() {
    if (!isRecording) {
        await startRecording();
    } else {
        stopRecording();
    }
}

async function startRecording() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            }
        });
        
        mediaRecorder = new MediaRecorder(stream, {
            mimeType: 'audio/webm;codecs=opus'
        });
        
        recordedChunks = [];
        recordingSeconds = 0;
        recordingStartTime = Date.now();
        
        // Set up recording events
        mediaRecorder.ondataavailable = function(event) {
            if (event.data.size > 0) {
                recordedChunks.push(event.data);
            }
        };
        
        mediaRecorder.onstop = function() {
            const blob = new Blob(recordedChunks, { type: 'audio/webm' });
            const audioUrl = URL.createObjectURL(blob);
            
            // Show preview
            const recordedAudio = document.getElementById('recorded-audio');
            const audioPreview = document.getElementById('audio-preview');
            const recordedAudioFile = document.getElementById('recorded-audio-file');
            
            if (recordedAudio && audioPreview) {
                recordedAudio.src = audioUrl;
                audioPreview.classList.remove('hidden');
                
                // Create file for form submission
                const file = new File([blob], `recording-${Date.now()}.webm`, { type: 'audio/webm' });
                const dataTransfer = new DataTransfer();
                dataTransfer.items.add(file);
                recordedAudioFile.files = dataTransfer.files;
            }
        };
        
        // Start recording
        mediaRecorder.start();
        isRecording = true;
        
        // Update UI
        updateRecordingUI();
        startTimer();
        startVisualizer(stream);
        enableNavigationWarning();
        saveState();
        
    } catch (error) {
        console.error('Error accessing microphone:', error);
        showRecordingError();
    }
}

function stopRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        
        // Stop all tracks
        mediaRecorder.stream.getTracks().forEach(track => track.stop());
        
        // Update UI
        updateRecordingUI();
        stopTimer();
        stopVisualizer();
        saveState();
        
        // Sync live observations to preview
        syncObservationsToPreview();
    }
}

function resetRecording() {
    // Stop current recording if active
    if (isRecording) {
        stopRecording();
    }
    
    // Reset UI
    const audioPreview = document.getElementById('audio-preview');
    const recordedAudio = document.getElementById('recorded-audio');
    const therapeuticObservations = document.getElementById('therapeutic-observations');
    
    if (audioPreview) audioPreview.classList.add('hidden');
    if (recordedAudio) recordedAudio.src = '';
    if (therapeuticObservations) therapeuticObservations.value = '';
    
    // Reset state
    recordedChunks = [];
    recordingSeconds = 0;
    recordingStartTime = null;
    
    updateRecordingUI();
    clearState();
    disableNavigationWarning();
}

function syncObservationsToPreview() {
    const liveObservations = document.getElementById('live-therapeutic-observations');
    const therapeuticObservations = document.getElementById('therapeutic-observations');
    
    if (liveObservations && therapeuticObservations) {
        therapeuticObservations.value = liveObservations.value;
    }
}

function showRecordingPreview() {
    if (recordedChunks.length > 0) {
        const recordedAudio = document.getElementById('recorded-audio');
        const audioPreview = document.getElementById('audio-preview');
        const recordedAudioFile = document.getElementById('recorded-audio-file');
        
        if (recordedAudio && audioPreview) {
            const blob = new Blob(recordedChunks, { type: 'audio/webm' });
            const audioUrl = URL.createObjectURL(blob);
            recordedAudio.src = audioUrl;
            audioPreview.classList.remove('hidden');
            
            // Create file for form submission
            const file = new File([blob], `recording-${Date.now()}.webm`, { type: 'audio/webm' });
            const dataTransfer = new DataTransfer();
            dataTransfer.items.add(file);
            recordedAudioFile.files = dataTransfer.files;
        }
    }
}

function updateRecordingUI() {
    const recordToggle = document.getElementById('record-toggle');
    const recordIcon = document.getElementById('record-icon');
    const recordIconPath = document.getElementById('record-icon-path');
    const recordingPulse = document.getElementById('recording-pulse');
    const recordingIndicator = document.getElementById('recording-indicator');
    const recordInstruction = document.getElementById('record-instruction');
    const audioVisualizer = document.getElementById('audio-visualizer');
    
    if (isRecording) {
        // Recording state
        recordToggle.classList.remove('bg-blue-600', 'hover:bg-blue-700');
        recordToggle.classList.add('bg-red-600', 'hover:bg-red-700');
        
        recordIconPath.setAttribute('d', 'M5.25 7.5A2.25 2.25 0 017.5 5.25h9a2.25 2.25 0 012.25 2.25v9a2.25 2.25 0 01-2.25 2.25h-9a2.25 2.25 0 01-2.25-2.25v-9z');
        
        recordingPulse.classList.remove('opacity-0');
        recordingPulse.classList.add('animate-ping');
        
        recordingIndicator.classList.remove('hidden');
        recordInstruction.textContent = 'Klicken zum Stoppen';
        audioVisualizer.classList.remove('hidden');
        
    } else {
        // Idle state
        recordToggle.classList.remove('bg-red-600', 'hover:bg-red-700');
        recordToggle.classList.add('bg-blue-600', 'hover:bg-blue-700');
        
        recordIconPath.setAttribute('d', 'M19 9v3a5.006 5.006 0 0 1-5 5h-4a5.006 5.006 0 0 1-5-5V9m7 9v3m-3 0h6M11 3h2a3 3 0 0 1 3 3v5a3 3 0 0 1-3 3h-2a3 3 0 0 1-3-3V6a3 3 0 0 1 3-3Z');
        
        recordingPulse.classList.add('opacity-0');
        recordingPulse.classList.remove('animate-ping');
        
        recordingIndicator.classList.add('hidden');
        recordInstruction.textContent = 'Klicken zum Starten';
        audioVisualizer.classList.add('hidden');
    }
}

function startTimer() {
    recordingTimer = setInterval(() => {
        recordingSeconds++;
        const minutes = Math.floor(recordingSeconds / 60);
        const seconds = recordingSeconds % 60;
        const timeDisplay = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
        
        const recordingTime = document.getElementById('recording-time');
        if (recordingTime) {
            recordingTime.textContent = timeDisplay;
        }
    }, 1000);
}

function stopTimer() {
    if (recordingTimer) {
        clearInterval(recordingTimer);
        recordingTimer = null;
    }
}

function startVisualizer(stream) {
    const canvas = document.getElementById('visualizer-canvas');
    if (!canvas) return;
    
    const canvasCtx = canvas.getContext('2d');
    
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    analyser = audioContext.createAnalyser();
    const source = audioContext.createMediaStreamSource(stream);
    
    analyser.fftSize = 256;
    const bufferLength = analyser.frequencyBinCount;
    dataArray = new Uint8Array(bufferLength);
    
    source.connect(analyser);
    
    function draw() {
        if (!isRecording) return;
        
        animationId = requestAnimationFrame(draw);
        
        analyser.getByteFrequencyData(dataArray);
        
        canvasCtx.fillStyle = 'rgb(249, 250, 251)';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
        
        const barWidth = (canvas.width / bufferLength) * 2.5;
        let barHeight;
        let x = 0;
        
        for (let i = 0; i < bufferLength; i++) {
            barHeight = (dataArray[i] / 255) * canvas.height * 0.8;
            
            const gradient = canvasCtx.createLinearGradient(0, canvas.height - barHeight, 0, canvas.height);
            gradient.addColorStop(0, 'rgb(59, 130, 246)');
            gradient.addColorStop(1, 'rgb(147, 197, 253)');
            
            canvasCtx.fillStyle = gradient;
            canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
            
            x += barWidth + 1;
        }
    }
    
    draw();
}

function stopVisualizer() {
    if (animationId) {
        cancelAnimationFrame(animationId);
        animationId = null;
    }
    
    if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
        audioContext = null;
    }
}

function showRecordingError() {
    const errorDiv = document.getElementById('recording-error');
    if (errorDiv) {
        errorDiv.classList.remove('hidden');
    }
}

    // Auto-save live observations
    function setupLiveObservationsSync() {
        const liveObservations = document.getElementById('live-therapeutic-observations');
        if (liveObservations) {
            liveObservations.addEventListener('input', function() {
                saveState();
            });
        }
    }

    // Handle form submission to include therapeutic observations
    document.addEventListener('submit', function(e) {
        if (e.target.closest('#audio-record-tab')) {
            const therapeuticObservations = document.getElementById('therapeutic-observations');
            const therapeuticObservationsInput = document.getElementById('therapeutic-observations-input');
            
            if (therapeuticObservations && therapeuticObservationsInput) {
                therapeuticObservationsInput.value = therapeuticObservations.value;
            }
            
            // Clear state on successful submission
            disableNavigationWarning();
            clearState();
        }
    });

    // Modal event handling
    document.addEventListener('click', function(e) {
        if (e.target.matches('[data-modal-target="audio-input-modal"]')) {
            setTimeout(() => {
                switchAudioTab('record');
                initializeModal();
                setupLiveObservationsSync();
            }, 200);
        }
    });

    // Page visibility change - save state when tab becomes hidden
    document.addEventListener('visibilitychange', function() {
        if (document.hidden && (isRecording || recordedChunks.length > 0)) {
            saveState();
        }
    });

    // Initialize with record tab active on page load
    document.addEventListener('DOMContentLoaded', function() {
        switchAudioTab('record');
    });

})();
</script> 